# 因子分解机做推荐预测任务

### 1.因子分解的含义

##### 分解机中的分解是来自于其在求解特征交叉项系数的时候用到了矩阵分解，其在逻辑回归的基础上引入了一个特征交叉项，也即考虑了不同特征之间的关系，因为数据系数的原因直接通过观测值来代表特征交叉项的系数会导致大部分数据因为系数（某些特征交叉项系数为0）为0而无法发挥作用；

### 2.因子分解机表达式，以二阶特征交叉为例

### $$线性回归的表达式为:\hat{y}=\omega_{0}+\sum^{n}\limits_{i=1}\omega_{i}x_{i}$$

### $$FM二阶特征交叉表达式为:\hat{y}=\omega_{0}+\sum\limits_{i=1}^{n}\omega_{i}x_{i}+\sum^{n-1}\limits_{i=1}\sum^{n}\limits_{j=i+1}\omega_{ij}x_{i}x_{j}$$

##### 相较于之前的线性回归方法，FM考虑了不同特征之间的交叉关系，现在最关键的一点就是如何求解交叉特征的系数，最简单的方法是依据观测变量得出，但是这会面临数据系数的问题，最合理的方法是通过模型学习来获得;

### $$\omega_{ij}=\textless v_{i},v_{j}\textgreater=v_{i}\cdot v_{j},v_{i}=(v_{i1},v_{i2},...,v_{ik})^{T} \in \mathbb{R}^{k},i=1,2,..,n$$

### $$w_{ij}=v_{i}^{T}v_{j}=\sum^{k}\limits_{i=1}v_{ik}v_{jk},该表达式对应矩阵分解方法,因此模型的方法称之为因子分解机$$

### $$其满足当k足够大的时候,对于任意对称正定实矩阵\hat{\omega}\in\mathbb{R}^{n\times n},均存在一个实矩阵v\in\mathbb{R}^{n\times k},使得\hat{\omega}=vv^{T}.因此vv^{T}的表达能力足够强$$

### 3.因子分解机一般步骤

- 数据处理与LR一致，将特征转换为数值型特征
- 结合业务构建FM模型
- 通过梯度下降算法更新模型参数
- 更具模型输出结果对商品进行排序，返回推荐列表

### 4.因子分解机的优缺点

- 优点
  - 引入隐向量可以很好地缓解数据稀疏带来的问题，使用该方法可以使得模型学习到不同特征交叉关系，并且使用隐向量，给定两个特征A和B,当A和B没有交互的时候，可以依据AC更新A，依据BD更新B，大幅度就降低了模型对数据稀疏性的要求；
  - 降低了最原始特征交叉的空间复杂度，最原始两两特征交叉需要O(n^2)，n表示特征数目，现在只需要nk(k远远小于n)个；
  - 其在一定程度上丢失了某些特征组合的精确记忆能力（例如有的特征交叉频繁，使用暴力特征交叉可以学到这一点，但是加入隐向量之后一些重要的交叉特征就变得平凡了），但是其大大提高了模型的泛化性能；
- 缺点
  - 在考虑高阶（三阶及以上）特征交叉的时候，会面临梯度爆炸的问题，降低了模型的学习能力

### 5.因子分解机后的改进版本

- FFM
  - 在FM的基础上引入特征域，其隐向量由原来的一维变成了多维，也就是说每一个特征对应的不是唯一一个隐向量，而是一组隐向量，给定三个特征A，B，C，在FM中每一个特征对应一个隐向量，分别为va,vb,vc，所以A与B的交叉特征的权重为(va,vb)，A与C的交叉特征的权重为(va,vc)，这里两个权重中使用的va是同一个隐向量；在FFM中会为每一个特征分配f-1个隐向量，f表示特征的数目，也即同样情况下A的隐向量表示为{vab,vac}，B的隐向量表示为{vba,vbc}，C的隐向量为{vca,vcb}，A与B的交叉特征的权重为(vab,vba)，A与C的交叉特征的权重为(vac,vca)，这样使得计算两个权重的时候不会互相干扰，增强了模型的表达和泛化能力；
  
  - ### $$\hat{y}=\omega_{0}+\sum\limits_{i=1}^{n}\omega_{i}x_{i}+\sum^{n-1}\limits_{i=1}\sum^{n}\limits_{j=i+1}(\omega_{j1,f2}\cdot\omega_{j2,f1})x_{i}x_{j}$$
  
  - 其参数数量可以表示为nxfxk，其中n表示特征数目，f表示特征域（一般为特征数目-1），k表示隐向量维度，这里其计算复杂度为O(kn^2)，其复杂度较于FM有显著的提升，但是其泛化能力有所提高；其和FM一样只适用于二阶特征交叉，三阶会导致梯度爆炸的问题；

### 6.python实现

### 7.参考资料

[1] 

[2] 王喆《深度学习推荐系统》

[3] [分解机推荐算法原理](https://www.cnblogs.com/pinard/p/6370127.html)

